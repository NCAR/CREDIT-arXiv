{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac814c7e-dee1-4b45-9239-8d9cd98b9ada",
   "metadata": {},
   "source": [
    "# Spatial correlation analysis - 6 hourly IFS\n",
    "\n",
    "* This notebook shows how spatial correlation was computed for upper air variables in 6 hourly IFS forecasts.\n",
    "\n",
    "* The notebook runs with `verif_config_6h.yml` in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8deb4be5-9191-4fb6-afb1-9b6c2351f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "\n",
    "sys.path.insert(0, os.path.realpath('../libs/'))\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6274de54-93d3-4a4a-9bd6-42df7be4ae4c",
   "metadata": {},
   "source": [
    "### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04614252-cb60-44ef-afa4-3732f1a34dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = os.path.realpath('verif_config_6h.yml')\n",
    "\n",
    "with open(config_name, 'r') as stream:\n",
    "    conf = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abf0008-758c-46c5-8378-1bdf403896bb",
   "metadata": {},
   "source": [
    "### Model and lead time to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df393c4-af29-4ef1-857c-403bd2342dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying lead times: [240]\n",
      "Verifying lead indices: [39]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'IFS'\n",
    "lead_range = conf[model_name]['lead_range']\n",
    "verif_lead_range = [240,]\n",
    "\n",
    "leads_exist = list(np.arange(lead_range[0], lead_range[-1]+lead_range[0], lead_range[0]))\n",
    "leads_verif = list(np.arange(verif_lead_range[0], verif_lead_range[-1]+verif_lead_range[0], verif_lead_range[0]))\n",
    "ind_lead = vu.lead_to_index(leads_exist, leads_verif)\n",
    "\n",
    "print('Verifying lead times: {}'.format(leads_verif))\n",
    "print('Verifying lead indices: {}'.format(ind_lead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78708828-93ce-4ac9-80dd-5f9b40cd80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "verif_ind_start = 0; verif_ind_end = 2*(365+366+365)\n",
    "path_verif = conf[model_name]['save_loc_verif']+'spatial_corr_{:04d}_{:04d}_{:03d}h_{}.nc'.format(\n",
    "    verif_ind_start, verif_ind_end, verif_lead_range[0], model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb12c4-f60e-4398-adde-bfb7367c544d",
   "metadata": {},
   "source": [
    "### Spatial correlation compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9d3246-64ea-497c-aeb2-9702b62fe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------ #\n",
    "# get forecast data\n",
    "filename_OURS = sorted(glob(conf[model_name]['save_loc_gather']+'*.nc'))\n",
    "\n",
    "# pick years\n",
    "year_range = conf[model_name]['year_range']\n",
    "years_pick = np.arange(year_range[0], year_range[1]+1, 1).astype(str)\n",
    "filename_OURS = [fn for fn in filename_OURS if any(year in fn for year in years_pick)]\n",
    "# filename_OURS = [fn for fn in filename_OURS if '00Z' in fn]\n",
    "\n",
    "L_max = len(filename_OURS)\n",
    "assert verif_ind_end <= L_max, 'verified indices (days) exceeds the max index available'\n",
    "\n",
    "filename_OURS = filename_OURS[verif_ind_start:verif_ind_end]\n",
    "variables_levels = {'V': None, 'U': None, 'T': None, 'Q': None}\n",
    "\n",
    "# ------------------------------------------------------------------------------------ #\n",
    "# allocate spatial corrlation on every 6 hour\n",
    "corr_ds_list = []\n",
    "\n",
    "# variables (time, level, latitude, longtude) to compute corr\n",
    "var_4D = list(variables_levels.keys())\n",
    "\n",
    "# loop over 6 hourly indices\n",
    "for idx, fn_ours in enumerate(filename_OURS):\n",
    "    \n",
    "    ds_ours = xr.open_dataset(fn_ours)\n",
    "    ds_ours = vu.ds_subset_everything(ds_ours, variables_levels)\n",
    "    ds_ours = ds_ours.isel(time=ind_lead[0])\n",
    "    ds_ours = ds_ours.load()\n",
    "\n",
    "    if idx == 0:\n",
    "        # get level information\n",
    "        levels = ds_ours['level'].values\n",
    "    \n",
    "    # create a list of var with level info\n",
    "    var_info = [(f\"{varname}_{level_num}\", varname, level_num) for varname in var_4D for level_num in levels]\n",
    "    \n",
    "    # get var names to label output xarray\n",
    "    varname_full = [var[0] for var in var_info]\n",
    "    N_vars = len(varname_full)\n",
    "    \n",
    "    # allocate xr.DataArray for corr output\n",
    "    corr_array = xr.DataArray(\n",
    "        np.full((N_vars, N_vars), np.nan),\n",
    "        coords={'var1': varname_full, 'var2': varname_full},\n",
    "        dims=['var1', 'var2']\n",
    "    )\n",
    "\n",
    "    # loop over variable pairs, compute corr\n",
    "    for (var1_info, var2_info) in combinations(var_info, 2):\n",
    "        \n",
    "        # var1\n",
    "        varname1, var1, lev1 = var1_info\n",
    "        data_target1 = ds_ours[var1].sel(level=lev1)\n",
    "\n",
    "        # var2\n",
    "        varname2, var2, lev2 = var2_info\n",
    "        data_target2 = ds_ours[var2].sel(level=lev2)\n",
    "        \n",
    "        # convert to numpy and ravel\n",
    "        data_target1 = data_target1.values.ravel()\n",
    "        data_target2 = data_target2.values.ravel()\n",
    "\n",
    "        # corr\n",
    "        corr, _ = pearsonr(data_target1, data_target2)\n",
    "        \n",
    "        # assign corr coef to corr_array\n",
    "        corr_array.loc[dict(var1=varname1, var2=varname2)] = corr\n",
    "        corr_array.loc[dict(var1=varname2, var2=varname1)] = corr\n",
    "\n",
    "    # set diagonal elements to 1\n",
    "    for varname in varname_full:\n",
    "        corr_array.loc[dict(var1=varname, var2=varname)] = 1.0\n",
    "\n",
    "    # convert xr.DataArray to xr.Dataset\n",
    "    corr_ds = xr.Dataset({'correlation': corr_array})\n",
    "\n",
    "    # Append the dataset to the list\n",
    "    corr_ds_list.append(corr_ds)\n",
    "\n",
    "# concat all 6 hourly result\n",
    "corr_ds_combined = xr.concat(corr_ds_list, dim='day')\n",
    "#corr_ds_combined.to_netcdf(path_verif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833de36-aa0d-4ead-bace-263cb32b03aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
